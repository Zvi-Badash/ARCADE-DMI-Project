{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from arcade_dataset import load_dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from model import VesselSegmentationModel\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open('model_overfit_config.yaml', 'r'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities, H_in, W_in = config['input']['image_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Custom colors for classes\n",
    "custom_colors = [\n",
    "    'tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', \n",
    "    'tab:brown', 'tab:pink', 'tab:olive', 'tab:cyan'\n",
    "]\n",
    "\n",
    "def get_color(category_id):\n",
    "    return custom_colors[category_id % len(custom_colors)]\n",
    "\n",
    "# Visualize the images and masks\n",
    "def visualize_batch(batch, num_classes=25, num_images=1):\n",
    "    fig, axes = plt.subplots(5, num_images, figsize=(20, 25))\n",
    "    \n",
    "    # Titles for each row\n",
    "    row_titles = ['Original Image', 'Transformed Image (Top Hat)', 'Transformed Image (Canny Edge)', 'Mask', 'Separate Masks']\n",
    "    \n",
    "    for row_idx, row_title in enumerate(row_titles):\n",
    "        # Display row title\n",
    "        axes[row_idx, 0].set_ylabel(row_title, fontsize=16, labelpad=20)\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            ax = axes[row_idx, i]\n",
    "            if row_idx == 0:  # Original Image\n",
    "                ax.imshow(batch['original_image'][i].squeeze().cpu().numpy(), cmap='gray')\n",
    "            elif row_idx == 1:  # Transformed Image (Top Hat)\n",
    "                ax.imshow(batch['transformed_image'][i].permute(1, 2, 0).cpu().numpy()[:,:,1], cmap='gray')\n",
    "            elif row_idx == 2:  # Transformed Image (Canny Edge)\n",
    "                ax.imshow(batch['transformed_image'][i].permute(1, 2, 0).cpu().numpy()[:,:,2], cmap='gray')\n",
    "            elif row_idx == 3:  # Mask\n",
    "                ax.imshow(batch['masks'][i].squeeze().cpu().numpy(), cmap='gray')\n",
    "            else:  # Separate Masks\n",
    "                ax.imshow(batch['original_image'][i].squeeze().cpu().numpy(), cmap='gray')\n",
    "                for class_id in range(num_classes):\n",
    "                    mask = batch['separate_masks'][i, class_id].cpu().numpy()\n",
    "                    if np.any(mask):\n",
    "                        color = get_color(class_id)\n",
    "                        contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        for contour in contours:\n",
    "                            ax.add_patch(patches.Polygon(contour.squeeze(), closed=True, fill=True, edgecolor=color, facecolor=color, alpha=0.3))\n",
    "                            x, y, w, h = cv2.boundingRect(contour)\n",
    "                            ax.add_patch(patches.Rectangle((x, y), w, h, linewidth=0.8, edgecolor=color, facecolor='none'))\n",
    "                            ax.text(x, y, str(class_id), fontsize=12, alpha=0.7, color=color)\n",
    "\n",
    "            # Add labels to the title of each image\n",
    "            if row_idx == 0:\n",
    "                labels = batch['labels'][i].cpu().numpy()\n",
    "                label_indices = np.where(labels == 1)[0]\n",
    "                ax.set_title(f\"Labels: {', '.join(map(str, label_indices))}\", fontsize=12)\n",
    "            \n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VesselSegmentationModel(modalities).to(device)\n",
    "model(torch.randn(1, modalities, H_in, W_in).to(device))\n",
    "\n",
    "## Format number of parameters nicely\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit the model on a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(split='train')\n",
    "next(iter(dataset)).keys()\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch(batch, num_classes=25, num_images=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['optimization']['learning_rate'] / 3)\n",
    "# losses = []\n",
    "progress_bar = tqdm(range(config['optimization']['epochs']))\n",
    "for epoch in progress_bar:\n",
    "    model.train()\n",
    "    x, y_gt = batch['transformed_image'].to(device), batch['separate_masks'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    loss = model._loss(x, y_gt, labels)[0]\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    progress_bar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "    progress_bar.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses[:])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the output of the model\n",
    "model.eval()\n",
    "x, y_gt = batch['transformed_image'].to(device), batch['separate_masks'].to(device)\n",
    "decoder_output, vae_output, _, labels, _ = model(x)\n",
    "\n",
    "print(f'GT Labels: {batch[\"labels\"][1].cpu().numpy()}, Predicted Labels: {labels[1].detach().cpu().numpy() > 0.001}')\n",
    "\n",
    "for c in range(25):\n",
    "    plt.subplots(figsize=(15, 5), ncols=4)\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(x[1, 0, :, :].cpu().numpy(), cmap='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(y_gt[1, c, :, :].cpu().numpy(), cmap='gray')\n",
    "    plt.title('Ground Truth Mask')\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(decoder_output[1, c, :, :].detach().cpu().numpy(), cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(vae_output[1, 0, :, :].detach().cpu().numpy(), cmap='gray')\n",
    "    plt.title('VAE Output')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
